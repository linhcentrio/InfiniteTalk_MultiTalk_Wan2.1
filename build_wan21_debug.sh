#!/bin/bash
# build_wan21_debug.sh - Build WAN2.1 InfiniteTalk/MultiTalk Docker Image
# Optimized for PyTorch 2.7.1 + CUDA 12.6

echo "ğŸš€ Building WAN2.1 InfiniteTalk/MultiTalk vá»›i PyTorch 2.7.1 optimization..."

# Set build environment
export DOCKER_BUILDKIT=1
export BUILDKIT_PROGRESS=plain

# Build information
BUILD_TAG="wan21-infinitetalk:v2.7.1-optimized"
BUILD_TIME=$(date +"%Y%m%d_%H%M%S")

echo "ğŸ“¦ Build Info:"
echo "   Tag: $BUILD_TAG" 
echo "   Time: $BUILD_TIME"
echo "   Base: spxiong/pytorch:2.7.1-py3.10.15-cuda12.6.0-ubuntu22.04"

# Build vá»›i optimized caching vÃ  logging
echo "ğŸ”¨ Starting build process..."
docker build \
    --no-cache \
    --progress=plain \
    --build-arg BUILDKIT_INLINE_CACHE=1 \
    -t $BUILD_TAG \
    -f Dockerfile . 2>&1 | tee build_${BUILD_TIME}.log

# Check build success
BUILD_STATUS=${PIPESTATUS[0]}
if [ $BUILD_STATUS -ne 0 ]; then
    echo "âŒ Build FAILED vá»›i exit code $BUILD_STATUS"
    echo "ğŸ“‹ Check build log: build_${BUILD_TIME}.log"
    exit $BUILD_STATUS
fi

echo "âœ… Build SUCCESS! Báº¯t Ä‘áº§u comprehensive verification..."

# ===== COMPREHENSIVE VERIFICATION =====
echo "ğŸ” === SYSTEM VERIFICATION ==="

# Check PyTorch vÃ  CUDA
echo "ğŸ“Š PyTorch & CUDA Check:"
docker run --rm --gpus all $BUILD_TAG python -c "
import torch
import sys
print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… CUDA Available: {torch.cuda.is_available()}')
print(f'âœ… CUDA Version: {torch.version.cuda}')
print(f'âœ… GPU Count: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'âœ… GPU Name: {torch.cuda.get_device_name(0)}')
    print(f'âœ… GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
"

# Check core packages
echo "ğŸ“¦ Core Packages Check:"
docker run --rm $BUILD_TAG python -c "
packages = ['torch', 'torchvision', 'diffusers', 'transformers', 'accelerate', 'xformers', 'runpod', 'minio']
for pkg in packages:
    try:
        module = __import__(pkg)
        version = getattr(module, '__version__', 'unknown')
        print(f'âœ… {pkg}: {version}')
    except ImportError:
        print(f'âŒ {pkg}: NOT INSTALLED')
"

# Check advanced packages
echo "ğŸ”§ Advanced Packages Check:"  
docker run --rm $BUILD_TAG python -c "
import sys
advanced_packages = {
    'flash_attn': 'FlashAttention',
    'sageattention': 'SageAttention', 
    'triton': 'Triton'
}
for pkg, name in advanced_packages.items():
    try:
        module = __import__(pkg)
        version = getattr(module, '__version__', 'unknown')
        print(f'âœ… {name}: {version}')
    except ImportError:
        print(f'âš ï¸ {name}: Not available (optional)')
"

# Check ComfyUI import
echo "ğŸ¨ ComfyUI Integration Check:"
docker run --rm $BUILD_TAG python -c "
import sys
sys.path.insert(0, '/app/ComfyUI')
try:
    import nodes
    print('âœ… ComfyUI nodes import: OK')
    import execution
    print('âœ… ComfyUI execution import: OK')
except Exception as e:
    print(f'âš ï¸ ComfyUI import issue: {e}')
"

# ===== MODEL VERIFICATION =====
echo "ğŸ¤– === MODEL VERIFICATION ==="
docker run --rm $BUILD_TAG python -c "
import os

# Core models
models = {
    'WAN2.1 Base': '/app/ComfyUI/models/diffusion_models/wan2.1-i2v-14b-480p-Q4_K_M.gguf',
    'Text Encoder': '/app/ComfyUI/models/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors',
    'VAE': '/app/ComfyUI/models/vae/wan_2.1_vae.safetensors',
    'CLIP Vision': '/app/ComfyUI/models/clip_vision/clip_vision_h.safetensors',
    'MultiTalk': '/app/ComfyUI/models/diffusion_models/WanVideo_2_1_Multitalk_14B_fp8_e4m3fn.safetensors',
    'InfiniteTalk': '/app/ComfyUI/models/diffusion_models/Wan2_1-InfiniteTalk-Multi_fp16.safetensors',
    'Wav2Vec': '/app/ComfyUI/models/transformers/chinese-wav2vec2-base-fairseq-ckpt.pt',
    'Speed LoRA': '/app/ComfyUI/models/loras/lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors'
}

total_size = 0
for name, path in models.items():
    if os.path.exists(path):
        size = os.path.getsize(path) / 1024**3  # GB
        total_size += size
        print(f'âœ… {name}: {size:.2f} GB')
    else:
        print(f'âŒ {name}: MISSING')

print(f'ğŸ“Š Total model size: {total_size:.2f} GB')
"

# ===== CUSTOM NODES VERIFICATION =====
echo "ğŸ”Œ === CUSTOM NODES VERIFICATION ==="
docker run --rm $BUILD_TAG python -c "
import os
import sys

# Check custom nodes
custom_nodes = [
    '/app/ComfyUI/custom_nodes/ComfyUI_WanVideoWrapper',
    '/app/ComfyUI/custom_nodes/audio_separation_nodes_comfyui'
]

for node_path in custom_nodes:
    node_name = os.path.basename(node_path)
    if os.path.exists(node_path):
        print(f'âœ… {node_name}: Installed')
        # Check if has __init__.py or main files
        files = os.listdir(node_path)
        py_files = [f for f in files if f.endswith('.py')]
        print(f'   ğŸ“„ Python files: {len(py_files)}')
    else:
        print(f'âŒ {node_name}: Missing')
"

# ===== CONTAINER HEALTH TEST =====
echo "ğŸ¥ === CONTAINER HEALTH TEST ==="
echo "â±ï¸ Starting container health test (30s timeout)..."
CONTAINER_ID=$(docker run -d --gpus all $BUILD_TAG)
sleep 10

# Check if container is still running
if docker ps | grep -q $CONTAINER_ID; then
    echo "âœ… Container startup: SUCCESS"
    
    # Check health status
    HEALTH_STATUS=$(docker inspect $CONTAINER_ID --format='{{.State.Health.Status}}' 2>/dev/null || echo "no-health-check")
    echo "ğŸ¥ Health status: $HEALTH_STATUS"
    
    # Get container logs
    echo "ğŸ“‹ Container logs (last 10 lines):"
    docker logs $CONTAINER_ID --tail 10
else
    echo "âŒ Container startup: FAILED"
    echo "ğŸ“‹ Container logs:"
    docker logs $CONTAINER_ID
fi

# Cleanup
docker stop $CONTAINER_ID >/dev/null 2>&1
docker rm $CONTAINER_ID >/dev/null 2>&1

# ===== FINAL SUMMARY =====
echo ""
echo "ğŸ‰ === BUILD VERIFICATION COMPLETE ==="
echo "ğŸ“¦ Image: $BUILD_TAG"
echo "ğŸ“‹ Build log: build_${BUILD_TIME}.log"
echo "ğŸ’¾ Image size:"
docker images $BUILD_TAG --format "table {{.Repository}}:{{.Tag}}\t{{.Size}}"

echo ""
echo "ğŸš€ Ready for deployment! Usage:"
echo "   docker run --gpus all -p 8000:8000 $BUILD_TAG"
echo ""
echo "ğŸ“Š Äá»ƒ test RunPod deployment:"
echo "   docker run --gpus all -e RUNPOD_AI_API_KEY=\$YOUR_KEY $BUILD_TAG"
echo ""
echo "âœ… Build vÃ  verification hoÃ n táº¥t!"
